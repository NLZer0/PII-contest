{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from importlib import reload\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from lstm_model import BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_label_split(data, label, train_size=0.7):\n",
    "    randidx = np.arange(len(data))\n",
    "    data_train, data_test = train_test_split(data, randidx, train_size)\n",
    "    label_train, label_test = train_test_split(label, randidx, train_size)\n",
    "\n",
    "    return data_train, data_test, label_train, label_test\n",
    "\n",
    "def train_test_split(data, randidx, train_size):\n",
    "    N = len(data)\n",
    "    return [data[i] for i in randidx[:int(train_size*N)]], [data[i] for i in randidx[int(train_size*N):]]\n",
    "\n",
    "def shuffle_data_label_lists(data, label):\n",
    "    randidx = np.arange(len(data))\n",
    "    np.random.shuffle(randidx)\n",
    "    return [data[i] for i in randidx], [label[i] for i in randidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, nclasses, device) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim).to(device)\n",
    "        self.lstm_model = nn.LSTM(embedding_dim, hidden_size//2, bidirectional=True).to(device)\n",
    "        self.ffwd_lay = nn.Linear(hidden_size, nclasses).to(device)\n",
    "        self.softmax = nn.Softmax(dim=2).to(device)\n",
    "\n",
    "        self.optim = torch.optim.Adam(self.parameters(), lr=1e-2)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def forward(self, batch):\n",
    "        out = self.embedding(batch) # L x vocab_size -> L x embedding_dim\n",
    "        out = self.lstm_model(out)[0] # L x hidden_size\n",
    "        out = self.ffwd_lay(out) # L x nclasses\n",
    "        return self.softmax(out)\n",
    "\n",
    "\n",
    "    def fit(self, train_data, nepochs, lr, device):\n",
    "        self.train()\n",
    "        self.to(device)\n",
    "\n",
    "        for g in self.optim.param_groups:\n",
    "            g['lr'] = lr    \n",
    "        \n",
    "        for ep in tqdm(range(nepochs)):\n",
    "            eploss = 0\n",
    "\n",
    "            for batch in train_data:\n",
    "                batch_X, batch_Y = batch[:,:,0], batch[:,:,1]\n",
    "                predict = self.forward(batch_X.to(device))\n",
    "                \n",
    "                self.optim.zero_grad()\n",
    "                loss = self.criterion(predict.swapaxes(1,2), batch_Y.to(device))\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "                eploss += loss.item()\n",
    "            \n",
    "            printbool = ep % (nepochs//10) == 0 if nepochs > 10 else True\n",
    "            if printbool:\n",
    "                print(f'Train loss: {eploss/len(train_data):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4957b5354ce4c62bfc5799f6a82e567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7618fda3ea5642909ea7ee85a3821da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encoding tokens and labels\n",
    "with open('data/mixtral-8x7b-v1.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "unique_tokens, unique_labels = set(), set()\n",
    "for doc_i, doc in enumerate(tqdm(data)):\n",
    "    unique_tokens |= set(np.unique(doc['tokens']))\n",
    "    unique_labels |= set(np.unique(doc['labels']))\n",
    "\n",
    "token2num = dict(zip(unique_tokens, range(1, len(unique_tokens)+1)))\n",
    "label2num = {\n",
    "    'O': 0,\n",
    "    'B-URL_PERSONAL': 0, \n",
    "    'I-URL_PERSONAL': 0, \n",
    "    'B-ID_NUM': 0, \n",
    "    'I-ID_NUM': 0, \n",
    "    'B-EMAIL': 0, \n",
    "    'I-EMAIL': 0,\n",
    "    'B-NAME_STUDENT': 1, \n",
    "    'I-NAME_STUDENT': 1, \n",
    "    'B-PHONE_NUM': 0, \n",
    "    'I-PHONE_NUM': 0, \n",
    "    'B-USERNAME': 0,\n",
    "    'I-USERNAME': 0, \n",
    "    'B-STREET_ADDRESS': 0, \n",
    "    'I-STREET_ADDRESS': 0, \n",
    "}\n",
    "num2token = {}\n",
    "for it in token2num:\n",
    "    num2token[token2num[it]] = it\n",
    "\n",
    "\n",
    "# load data and split by sentences\n",
    "sentences = []\n",
    "cur_sentence = []\n",
    "sentences_labels = []\n",
    "cur_sentences_labels = []\n",
    "\n",
    "max_len = 200\n",
    "for doc_i, doc in enumerate(tqdm(data)):\n",
    "    for token, label in zip(data[doc_i]['tokens'], data[doc_i]['labels']):\n",
    "        cur_sentence.append(token2num[token])\n",
    "        cur_sentences_labels.append(label2num[label])\n",
    "\n",
    "        if (token == '.') | (token.endswith('\\n')) | (token == '?') | (token == '!'):   \n",
    "            # if sum(cur_sentences_labels) > 0:\n",
    "            if len(cur_sentence) < max_len:\n",
    "                sentences.append(torch.LongTensor(cur_sentence))\n",
    "                sentences_labels.append(torch.LongTensor(cur_sentences_labels))\n",
    "\n",
    "            cur_sentences_labels = []\n",
    "            cur_sentence = []\n",
    "    \n",
    "    if sum(cur_sentences_labels) > 0:\n",
    "        sentences.append(cur_sentence)\n",
    "        sentences_labels.append(cur_sentences_labels)\n",
    "\n",
    "    cur_sentences_labels = []\n",
    "    cur_sentence = []\n",
    "\n",
    "\n",
    "# create train and test df \n",
    "name_sentences_labels = []\n",
    "name_sentences = []\n",
    "\n",
    "username_sentences_labels = []\n",
    "username_sentences = []\n",
    "\n",
    "o_sentences_labels = []\n",
    "o_sentences = []\n",
    "\n",
    "for i, it in enumerate(sentences):\n",
    "    if 1 in sentences_labels[i]:\n",
    "        name_sentences_labels.append(sentences_labels[i])\n",
    "        name_sentences.append(sentences[i])\n",
    "    if 2 in sentences_labels[i]:\n",
    "        username_sentences.append(sentences[i])\n",
    "        username_sentences_labels.append(sentences_labels[i])\n",
    "    else:\n",
    "        o_sentences.append(sentences[i])\n",
    "        o_sentences_labels.append(sentences_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = list(map(len, o_sentences))\n",
    "max_len = max(seq_len)\n",
    "o_sentences_ten = torch.cat([F.pad(o_sentences[i], (0, max_len-seq_len[i])).reshape(1,-1) for i in range(len(o_sentences))])\n",
    "o_sentences_ten = pack_padded_sequence(o_sentences_ten, seq_len, batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_sentences_train, name_sentences_test, name_sentences_labels_train, name_sentences_labels_test = data_label_split(name_sentences, name_sentences_labels, train_size=0.8)\n",
    "user_sentences_train, user_sentences_test, user_sentences_labels_train, user_sentences_labels_test = data_label_split(username_sentences, username_sentences_labels, train_size=0.8)\n",
    "o_sentences_train, o_sentences_test, o_sentences_labels_train, o_sentences_labels_test = data_label_split(o_sentences, o_sentences_labels, train_size=0.8)\n",
    "\n",
    "# sentences_train = o_sentences_train + name_sentences_train*280 + user_sentences_train*40_000\n",
    "# sentences_labels_train = o_sentences_labels_train + name_sentences_labels_train*280 + user_sentences_labels_train*40_000\n",
    "\n",
    "# sentences_test = o_sentences_test + name_sentences_test*280 + user_sentences_test*40_000\n",
    "# sentences_labels_test = o_sentences_labels_test + name_sentences_labels_test*280 + user_sentences_labels_test*40_000\n",
    "\n",
    "sentences_train = o_sentences_train + name_sentences_train*280\n",
    "sentences_labels_train = o_sentences_labels_train + name_sentences_labels_train*280\n",
    "\n",
    "sentences_test = o_sentences_test + name_sentences_test*280\n",
    "sentences_labels_test = o_sentences_labels_test + name_sentences_labels_test*280\n",
    "\n",
    "sentences_train, sentences_labels_train = shuffle_data_label_lists(sentences_train, sentences_labels_train)\n",
    "sentences_test, sentences_labels_test = shuffle_data_label_lists(sentences_test, sentences_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train = torch.cat(sentences_train, dim=0)\n",
    "sentences_labels_train = torch.cat(sentences_labels_train, dim=0)\n",
    "\n",
    "sentences_test = torch.cat(sentences_test, dim=0)\n",
    "sentences_labels_test = torch.cat(sentences_labels_test, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = torch.cat((sentences_train.unsqueeze(2), sentences_labels_train.unsqueeze(2)), dim=2)\n",
    "train_data = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "test_data = torch.cat((sentences_test.unsqueeze(2), sentences_labels_test.unsqueeze(2)), dim=2)\n",
    "test_data = DataLoader(test_data, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# fit lstm\n",
    "model = BiLSTM(\n",
    "    vocab_size=len(token2num)+1,\n",
    "    embedding_dim=32,\n",
    "    hidden_size=16,\n",
    "    nclasses=2,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032276170f1849aa8cbd6f4fd4a2cd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.314\n",
      "Train loss: 0.313\n",
      "Train loss: 0.313\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# fit bi-lstm\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [3], line 41\u001b[0m, in \u001b[0;36mBiLSTM.fit\u001b[1;34m(self, train_data, nepochs, lr, device)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     40\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(predict\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m), batch_Y\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m---> 41\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     44\u001b[0m eploss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\zmitrovich.nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zmitrovich.nik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit bi-lstm\n",
    "model.fit(\n",
    "    train_data=train_data,\n",
    "    nepochs=10,\n",
    "    lr=1e-2,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train BA: 0.991\n",
      "Test BA: 0.785\n"
     ]
    }
   ],
   "source": [
    "# get train test metrics\n",
    "predict_train_label = []\n",
    "train_label = []\n",
    "with torch.no_grad():\n",
    "    for batch in train_data:\n",
    "        batch_X, batch_Y = batch[:,:,0], batch[:,:,1]\n",
    "        predict = torch.argmax(model.forward(batch_X.to(device)).cpu(), dim=2).reshape(-1)\n",
    "        predict_train_label.append(predict)\n",
    "        train_label.append(batch_Y.reshape(-1))\n",
    "\n",
    "train_label = torch.cat(train_label)\n",
    "predict_train_label = torch.cat(predict_train_label)\n",
    "print(f'Train BA: {balanced_accuracy_score(train_label, predict_train_label):.3f}')\n",
    "\n",
    "predict_test_label = []\n",
    "test_label = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_data:\n",
    "        batch_X, batch_Y = batch[:,:,0], batch[:,:,1]\n",
    "        predict = torch.argmax(model.forward(batch_X.to(device)).cpu(), dim=2).reshape(-1)\n",
    "        predict_test_label.append(predict)\n",
    "        test_label.append(batch_Y.reshape(-1))\n",
    "\n",
    "test_label = torch.cat(test_label)\n",
    "predict_test_label = torch.cat(predict_test_label)\n",
    "print(f'Test BA: {balanced_accuracy_score(test_label, predict_test_label):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "[[102999686      2693]\n",
      " [     9470    546551]]\n",
      "Test\n",
      "[[25796045      235]\n",
      " [   58319    77201]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('Train')\n",
    "cfmatrix = confusion_matrix(train_label, predict_train_label)\n",
    "print(cfmatrix)\n",
    "\n",
    "print('Test')\n",
    "cfmatrix = confusion_matrix(test_label, predict_test_label)\n",
    "print(cfmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004a76e0cd1944e4b4581f2e3d8b91ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6807 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48cf6277fa29406e96118a44e176dc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/282905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split all df on sentences\n",
    "sentences_info = []\n",
    "cur_sentences_info = []\n",
    "\n",
    "sentences = []\n",
    "cur_sentence = []\n",
    "sentences_labels = []\n",
    "cur_sentences_labels = []\n",
    "\n",
    "for doc_i, doc in enumerate(tqdm(data)):\n",
    "    sentence_document = data[doc_i]['document']\n",
    "    for token_i, token, label in zip(range(len(data[doc_i]['tokens'])), data[doc_i]['tokens'], data[doc_i]['labels']):\n",
    "        cur_sentence.append(token2num[token])\n",
    "        cur_sentences_labels.append(label2num[label])\n",
    "        cur_sentences_info.append([sentence_document, token_i])\n",
    "\n",
    "        if (token == '.') | (token.endswith('\\n')) | (token == '?') | (token == '!'):   \n",
    "            # if sum(cur_sentences_labels) > 0:\n",
    "            sentences_info.append(torch.LongTensor(cur_sentences_info))\n",
    "            sentences.append(torch.LongTensor(cur_sentence))\n",
    "            sentences_labels.append(torch.LongTensor(cur_sentences_labels))\n",
    "\n",
    "            cur_sentences_info = []\n",
    "            cur_sentences_labels = []\n",
    "            cur_sentence = []\n",
    "    \n",
    "    if sum(cur_sentences_labels) > 0:\n",
    "        sentences_info.append(torch.LongTensor(cur_sentences_info))\n",
    "        sentences.append(torch.LongTensor(cur_sentence))\n",
    "        sentences_labels.append(torch.LongTensor(cur_sentences_labels))\n",
    "\n",
    "    cur_sentences_info = []\n",
    "    cur_sentences_labels = []\n",
    "    cur_sentence = []\n",
    "\n",
    "\n",
    "# get bi-lstm-predict and create result table\n",
    "results = []\n",
    "\n",
    "for i in tqdm(range(len(sentences))):\n",
    "    predict = torch.argmax(model.forward(sentences[i].unsqueeze(0).to(device)).cpu(), dim=2)[0]\n",
    "\n",
    "    for j in range(1, len(predict)):\n",
    "        if (predict[j-1] == 1) & (predict[j] == 1):\n",
    "            predict[j] = 3\n",
    "        elif ((predict[j-1] == 2) | (predict[j-1] == 4)) & (predict[j] == 2):\n",
    "            predict[j] = 4\n",
    "    \n",
    "    if (predict > 0).sum() > 0:\n",
    "        results.append(torch.cat((\n",
    "            sentences_info[i][predict > 0],\n",
    "            sentences[i][predict > 0].reshape(-1,1),\n",
    "            predict[predict > 0].reshape(-1,1)\n",
    "        ), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.cat(results)\n",
    "results = pd.DataFrame(results, columns=['document', 'token_i', 'token', 'label'])\n",
    "results['token'] = results.token.apply(lambda x: num2token[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token_i</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>69</td>\n",
       "      <td>Éditions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>482</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>741</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Diego</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12337</th>\n",
       "      <td>22679</td>\n",
       "      <td>236</td>\n",
       "      <td>purists</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12338</th>\n",
       "      <td>22681</td>\n",
       "      <td>545</td>\n",
       "      <td>spikes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12339</th>\n",
       "      <td>22687</td>\n",
       "      <td>52</td>\n",
       "      <td>auditing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12340</th>\n",
       "      <td>22687</td>\n",
       "      <td>115</td>\n",
       "      <td>auditing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12341</th>\n",
       "      <td>22687</td>\n",
       "      <td>326</td>\n",
       "      <td>auditing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11088 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       document  token_i     token  label\n",
       "0             7        9  Nathalie      1\n",
       "2             7       69  Éditions      1\n",
       "3             7      482  Nathalie      1\n",
       "5             7      741  Nathalie      1\n",
       "7            10        0     Diego      1\n",
       "...         ...      ...       ...    ...\n",
       "12337     22679      236   purists      1\n",
       "12338     22681      545    spikes      1\n",
       "12339     22687       52  auditing      1\n",
       "12340     22687      115  auditing      1\n",
       "12341     22687      326  auditing      1\n",
       "\n",
       "[11088 rows x 4 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = []\n",
    "for doc_i, doc in enumerate(data):\n",
    "    document_i = doc['document']\n",
    "    labels = doc['labels']\n",
    "    tokens = doc['tokens']\n",
    "    for i, lab in enumerate(labels):\n",
    "        if 'USERNAME' in lab:\n",
    "            real_df.append([doc_i, document_i, i, tokens[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.DataFrame(real_df, columns=['doc_i', 'document_i', 'row_i', 'token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in real_df['doc_i'].values:\n",
    "    with open(f'text_{i}.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(data[i]['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_i</th>\n",
       "      <th>document_i</th>\n",
       "      <th>row_i</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "      <td>3351</td>\n",
       "      <td>61</td>\n",
       "      <td>castanedagabriel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194</td>\n",
       "      <td>4462</td>\n",
       "      <td>4</td>\n",
       "      <td>fdixon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194</td>\n",
       "      <td>4462</td>\n",
       "      <td>582</td>\n",
       "      <td>fdixon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300</td>\n",
       "      <td>5716</td>\n",
       "      <td>1</td>\n",
       "      <td>meyermichelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>478</td>\n",
       "      <td>7786</td>\n",
       "      <td>623</td>\n",
       "      <td>jacob59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>550</td>\n",
       "      <td>8642</td>\n",
       "      <td>8</td>\n",
       "      <td>holmespatrick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_i  document_i  row_i             token\n",
       "0    114        3351     61  castanedagabriel\n",
       "1    194        4462      4            fdixon\n",
       "2    194        4462    582            fdixon\n",
       "3    300        5716      1     meyermichelle\n",
       "4    478        7786    623           jacob59\n",
       "5    550        8642      8     holmespatrick"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
